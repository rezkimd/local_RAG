{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 3.2. Proses Evaluasi untuk Setiap Siswa (Fokus pada RAG) ---\n",
    "\n",
    "# print(\"\\nMemulai proses evaluasi RAG untuk jawaban siswa...\")\n",
    "# all_evaluations = {}\n",
    "\n",
    "# # Filter untuk 5 mahasiswa pertama sesuai permintaan Anda\n",
    "# students_to_evaluate = ['M1', 'M2', 'M3', 'M4', 'M5']\n",
    "# # Mengambil data dari variabel student_answers_data yang sudah dimuat dari JSON\n",
    "# filtered_answers = [ans for ans in student_answers_data if ans[\"student_id\"] in students_to_evaluate]\n",
    "\n",
    "# # Loop utama untuk evaluasi\n",
    "# for student_ans in tqdm(filtered_answers, desc=\"Mengevaluasi Jawaban\"):\n",
    "#     student_id = student_ans[\"student_id\"]\n",
    "#     question_id = student_ans[\"question_id\"]\n",
    "\n",
    "#     if student_id not in all_evaluations:\n",
    "#         all_evaluations[student_id] = {}\n",
    "\n",
    "#     try:\n",
    "#         # Mencari teks pertanyaan yang sesuai\n",
    "#         question_text = next(q[\"question_text\"] for q in question_data if q[\"question_id\"] == question_id)\n",
    "#     except StopIteration:\n",
    "#         print(f\"Peringatan: Melewati jawaban untuk {student_id} karena question_id '{question_id}' tidak ditemukan di data soal.\")\n",
    "#         continue\n",
    "\n",
    "#     # --- Proses RAG ---\n",
    "#     # 1. Retrieval: Dapatkan embedding dari pertanyaan dan cari chunk yang relevan\n",
    "#     query_embedding = get_embeddings([question_text])[0]\n",
    "#     retrieved_chunks = retrieve_knowledge(query_embedding)\n",
    "\n",
    "#     # 2. Generation: Hasilkan evaluasi menggunakan Gemma dengan konteks yang ditemukan\n",
    "#     gemma_evaluation = generate_gemma_response(\n",
    "#         question_text,\n",
    "#         student_ans[\"original_text\"],\n",
    "#         retrieved_chunks\n",
    "#     )\n",
    "\n",
    "#     # --- Gabungkan semua hasil ke dalam dictionary ---\n",
    "#     all_evaluations[student_id][question_id] = {\n",
    "#         \"original_student_answer\": student_ans[\"original_text\"],\n",
    "#         \"retrieved_context\": \"\\n\\n\".join([c['text'] for c in retrieved_chunks]),\n",
    "#         \"simple_o_score\": None,  # Diatur ke None (akan menjadi null di JSON)\n",
    "#         \"gemma_evaluation\": gemma_evaluation\n",
    "#     }\n",
    "\n",
    "# print(\"\\nProses evaluasi RAG selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.2. Proses Evaluasi (UJI COBA untuk 3 Jawaban) ---\n",
    "\n",
    "# (1) Impor library tambahan\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "print(\"\\nMemulai proses evaluasi RAG (UJI COBA)...\")\n",
    "all_evaluations = {}\n",
    "timing_data = []\n",
    "\n",
    "# (2) AMBIL 3 JAWABAN PERTAMA UNTUK UJI COBA\n",
    "# Modifikasi utama ada di sini. Kita mengambil slice `[:3]` dari data utama.\n",
    "test_answers = student_answers_data[:3]\n",
    "print(f\"Memulai uji coba dengan {len(test_answers)} jawaban pertama...\")\n",
    "\n",
    "# (3) Loop utama untuk evaluasi HANYA pada data uji coba\n",
    "for student_ans in tqdm(test_answers, desc=\"Mengevaluasi 3 Jawaban Uji Coba\"):\n",
    "    # Catat waktu mulai\n",
    "    start_time = time.time()\n",
    "\n",
    "    student_id = student_ans[\"student_id\"]\n",
    "    question_id = student_ans[\"question_id\"]\n",
    "\n",
    "    if student_id not in all_evaluations:\n",
    "        all_evaluations[student_id] = {}\n",
    "\n",
    "    try:\n",
    "        question_text = next(\n",
    "            q[\"question_text\"] for q in question_data if q[\"question_id\"] == question_id\n",
    "        )\n",
    "    except StopIteration:\n",
    "        print(\n",
    "            f\"Peringatan: Melewati jawaban untuk {student_id} karena question_id '{question_id}' tidak ditemukan.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # --- Proses RAG ---\n",
    "    query_embedding = get_embeddings([question_text])[0]\n",
    "    retrieved_chunks = retrieve_knowledge(query_embedding)\n",
    "    gemma_evaluation = generate_gemma_response(\n",
    "        question_text, student_ans[\"original_text\"], retrieved_chunks\n",
    "    )\n",
    "\n",
    "    # --- Gabungkan hasil ---\n",
    "    all_evaluations[student_id][question_id] = {\n",
    "        \"original_student_answer\": student_ans[\"original_text\"],\n",
    "        \"retrieved_context\": \"\\n\\n\".join([c[\"text\"] for c in retrieved_chunks]),\n",
    "        \"simple_o_score\": None,\n",
    "        \"gemma_evaluation\": gemma_evaluation,\n",
    "    }\n",
    "\n",
    "    # (4) Catat waktu selesai dan simpan durasi\n",
    "    end_time = time.time()\n",
    "    evaluation_time = end_time - start_time\n",
    "    timing_data.append(\n",
    "        {\n",
    "            \"student_id\": student_id,\n",
    "            \"question_id\": question_id,\n",
    "            \"evaluation_time_seconds\": evaluation_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\nProses evaluasi RAG (UJI COBA) selesai.\")\n",
    "\n",
    "# Menyimpan hasil evaluasi dari uji coba\n",
    "output_eval_path = os.path.join(KB_PATH, \"test_3_evaluations.json\")\n",
    "with open(output_eval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_evaluations, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\nHasil evaluasi uji coba disimpan di: {output_eval_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# BAGIAN ANALISIS WAKTU (dari hasil uji coba)\n",
    "# ==============================================================================\n",
    "if timing_data:\n",
    "    print(\"\\n--- Analisis Waktu Evaluasi (dari hasil uji coba) ---\")\n",
    "\n",
    "    timing_df = pd.DataFrame(timing_data)\n",
    "    timing_csv_path = os.path.join(KB_PATH, \"test_3_timing_report.csv\")\n",
    "    timing_df.to_csv(timing_csv_path, index=False)\n",
    "    print(f\"Laporan waktu evaluasi uji coba telah disimpan di: {timing_csv_path}\")\n",
    "\n",
    "    print(\"\\nCuplikan Laporan Waktu:\")\n",
    "    print(timing_df.head())\n",
    "\n",
    "    print(\"\\nStatistik Waktu Evaluasi (detik):\")\n",
    "    print(timing_df[\"evaluation_time_seconds\"].describe())\n",
    "\n",
    "    print(\"\\nMembuat visualisasi plot...\")\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "    sns.barplot(\n",
    "        x=timing_df.index,\n",
    "        y=timing_df[\"evaluation_time_seconds\"],\n",
    "        ax=axes,\n",
    "        palette=\"rocket\",\n",
    "    )\n",
    "    axes.set_title(\"Waktu Evaluasi untuk 3 Jawaban Pertama\", fontsize=16)\n",
    "    axes.set_xlabel(\"Indeks Jawaban Uji Coba\", fontsize=12)\n",
    "    axes.set_ylabel(\"Waktu (detik)\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(KB_PATH, \"test_3_timing_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\"Plot visualisasi waktu uji coba telah disimpan di: {plot_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nTidak ada data waktu yang tercatat dari uji coba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "print(\"Mempersiapkan wrapper LLM yang kompatibel dengan LangChain...\")\n",
    "\n",
    "# 1. Buat text-generation pipeline dari Hugging Face\n",
    "gemma_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=gemma_model,\n",
    "    tokenizer=gemma_tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "# 2. Bungkus pipeline tersebut menggunakan HuggingFacePipeline dari LangChain\n",
    "# Objek 'langchain_llm' inilah yang akan kita berikan ke RAGAs\n",
    "langchain_llm = HuggingFacePipeline(pipeline=gemma_pipeline)\n",
    "\n",
    "print(\"Wrapper 'langchain_llm' berhasil dibuat dan siap digunakan untuk evaluasi.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# TAHAP 1: PERSIAPAN & PENGUMPULAN DATA\n",
    "# ==============================================================================\n",
    "# Gabungkan data soal dan data jawaban siswa menjadi satu DataFrame untuk kemudahan\n",
    "q_df = pd.DataFrame(question_data)\n",
    "s_df = pd.DataFrame(student_answers_data)\n",
    "# Lakukan join untuk mendapatkan teks pertanyaan untuk setiap jawaban siswa\n",
    "eval_prep_df = pd.merge(s_df, q_df, on=\"question_id\")\n",
    "\n",
    "print(f\"Total {len(eval_prep_df)} jawaban akan dievaluasi dalam mode batch.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# TAHAP 2: EKSEKUSI BATCH\n",
    "# ==============================================================================\n",
    "# --- Batch Retrieval ---\n",
    "print(\"\\nLangkah 1: Melakukan Embedding & Retrieval secara Batch...\")\n",
    "start_retrieval_time = time.time()\n",
    "\n",
    "# Ambil semua teks pertanyaan untuk di-embed sekaligus\n",
    "questions_to_embed = eval_prep_df[\"question_text\"].tolist()\n",
    "# Dapatkan semua embedding dalam satu panggilan\n",
    "all_embeddings = get_embeddings(questions_to_embed)\n",
    "# Lakukan pencarian FAISS untuk semua embedding sekaligus\n",
    "distances, indices = kbindex.search(all_embeddings, k=5)\n",
    "\n",
    "# Ambil teks dari chunk yang relevan berdasarkan hasil pencarian\n",
    "all_retrieved_contexts = []\n",
    "for i in range(len(indices)):\n",
    "    chunks = [knowledge_base_chunks[idx][\"text\"] for idx in indices[i] if idx != -1]\n",
    "    all_retrieved_contexts.append(\"\\n\\n\".join(chunks))\n",
    "\n",
    "eval_prep_df[\"retrieved_context\"] = all_retrieved_contexts\n",
    "end_retrieval_time = time.time()\n",
    "print(\n",
    "    f\"Embedding & Retrieval selesai dalam {end_retrieval_time - start_retrieval_time:.2f} detik.\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- Batch Generation ---\n",
    "print(\"\\nLangkah 2: Melakukan Evaluasi oleh Gemma secara Batch...\")\n",
    "# Buat daftar prompt lengkap untuk setiap baris data\n",
    "prompts = []\n",
    "for row_index, row in eval_prep_df.iterrows():\n",
    "    prompt = f\"\"\"Anda adalah seorang pengajar bahasa Jepang ahli.\n",
    "Tugas Anda adalah mengevaluasi jawaban esai siswa. Berikan umpan balik yang konstruktif.\n",
    "\n",
    "### Pertanyaan:\n",
    "{row['question_text']}\n",
    "\n",
    "### Jawaban Siswa:\n",
    "{row['original_text']}\n",
    "\n",
    "### Konteks/Referensi:\n",
    "{row['retrieved_context']}\n",
    "\n",
    "Silakan berikan evaluasi Anda:\"\"\"\n",
    "    prompts.append(prompt)\n",
    "\n",
    "# Catat waktu mulai untuk proses generation\n",
    "start_generation_time = time.time()\n",
    "\n",
    "# Panggil gemma_pipeline SATU KALI dengan semua prompt\n",
    "# gemma_pipeline sudah dikonfigurasi dengan batch_size di blok sebelumnya\n",
    "gemma_evaluations = gemma_pipeline(prompts)\n",
    "\n",
    "# Catat waktu selesai\n",
    "end_generation_time = time.time()\n",
    "\n",
    "# Ekstrak teks yang dihasilkan saja\n",
    "eval_prep_df[\"gemma_evaluation\"] = [\n",
    "    result[0][\"generated_text\"].replace(p, \"\").strip()\n",
    "    for p, result in zip(prompts, gemma_evaluations)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TAHAP 3: PENGUMPULAN HASIL & ANALISIS WAKTU\n",
    "# ==============================================================================\n",
    "total_generation_time = end_generation_time - start_generation_time\n",
    "average_time_per_answer = total_generation_time / len(eval_prep_df)\n",
    "\n",
    "print(f\"\\nProses evaluasi batch selesai.\")\n",
    "print(\n",
    "    f\"Total waktu untuk {len(eval_prep_df)} jawaban: {total_generation_time:.2f} detik.\"\n",
    ")\n",
    "print(f\"Rata-rata waktu per jawaban: {average_time_per_answer:.2f} detik.\")\n",
    "\n",
    "# Simpan hasil lengkap ke CSV\n",
    "batch_results_path = os.path.join(KB_PATH, \"batch_evaluation_results.csv\")\n",
    "eval_prep_df.to_csv(batch_results_path, index=False)\n",
    "print(f\"\\nHasil evaluasi batch lengkap disimpan di: {batch_results_path}\")\n",
    "\n",
    "# Tampilkan cuplikan hasil\n",
    "print(\"\\nCuplikan Hasil Evaluasi Batch:\")\n",
    "display(eval_prep_df[[\"student_id\", \"question_id\", \"gemma_evaluation\"]].head())\n",
    "\n",
    "\n",
    "# --- Visualisasi Waktu ---\n",
    "# Membuat DataFrame sederhana untuk plotting waktu rata-rata\n",
    "timing_summary = {\n",
    "    \"Total Jawaban\": len(eval_prep_df),\n",
    "    \"Total Waktu (detik)\": total_generation_time,\n",
    "    \"Rata-rata Waktu per Jawaban (detik)\": average_time_per_answer,\n",
    "}\n",
    "\n",
    "print(\"\\n--- Ringkasan Waktu Evaluasi ---\")\n",
    "print(pd.Series(timing_summary))\n",
    "\n",
    "# Plot sederhana untuk menunjukkan total vs rata-rata\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=list(timing_summary.keys())[1:], y=list(timing_summary.values())[1:])\n",
    "plt.title(\"Ringkasan Kinerja Waktu Evaluasi Batch\", fontsize=16)\n",
    "plt.ylabel(\"Waktu (detik)\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee93dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.2. Proses Evaluasi untuk Setiap Siswa (Dimodifikasi dengan Pencatatan Waktu) ---\n",
    "\n",
    "# (1) Impor library tambahan yang diperlukan untuk mencatat waktu dan visualisasi\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\nMemulai proses evaluasi RAG untuk semua jawaban siswa...\")\n",
    "all_evaluations = {}\n",
    "# (2) Inisialisasi list untuk menampung data waktu\n",
    "timing_data = []\n",
    "\n",
    "# (3) Loop utama untuk evaluasi pada SEMUA jawaban siswa (filter dihapus)\n",
    "# Kita langsung melakukan iterasi pada `student_answers_data`\n",
    "for student_ans in tqdm(student_answers_data, desc=\"Mengevaluasi Semua Jawaban\"):\n",
    "    # Catat waktu mulai untuk satu jawaban\n",
    "    start_time = time.time()\n",
    "\n",
    "    student_id = student_ans[\"student_id\"]\n",
    "    question_id = student_ans[\"question_id\"]\n",
    "\n",
    "    if student_id not in all_evaluations:\n",
    "        all_evaluations[student_id] = {}\n",
    "\n",
    "    try:\n",
    "        # Mencari teks pertanyaan yang sesuai.\n",
    "        question_text = next(\n",
    "            q[\"question_text\"] for q in question_data if q[\"question_id\"] == question_id\n",
    "        )\n",
    "    except StopIteration:\n",
    "        print(\n",
    "            f\"Peringatan: Melewati jawaban untuk {student_id} karena question_id '{question_id}' tidak ditemukan.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # --- Proses RAG ---\n",
    "    # 1. Retrieval\n",
    "    query_embedding = get_embeddings([question_text])[0]\n",
    "    retrieved_chunks = retrieve_knowledge(query_embedding)\n",
    "\n",
    "    # 2. Generation\n",
    "    gemma_evaluation = generate_gemma_response(\n",
    "        question_text, student_ans[\"original_text\"], retrieved_chunks\n",
    "    )\n",
    "\n",
    "    # --- Gabungkan semua hasil ke dalam dictionary ---\n",
    "    all_evaluations[student_id][question_id] = {\n",
    "        \"original_student_answer\": student_ans[\"original_text\"],\n",
    "        \"retrieved_context\": \"\\n\\n\".join([c[\"text\"] for c in retrieved_chunks]),\n",
    "        \"simple_o_score\": None,\n",
    "        \"gemma_evaluation\": gemma_evaluation,\n",
    "    }\n",
    "\n",
    "    # (4) Catat waktu selesai dan hitung durasi\n",
    "    end_time = time.time()\n",
    "    evaluation_time = end_time - start_time\n",
    "\n",
    "    # Tambahkan data waktu ke dalam list\n",
    "    timing_data.append(\n",
    "        {\n",
    "            \"student_id\": student_id,\n",
    "            \"question_id\": question_id,\n",
    "            \"evaluation_time_seconds\": evaluation_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\nProses evaluasi RAG selesai.\")\n",
    "\n",
    "# Menyimpan hasil evaluasi utama ke file JSON (seperti kode asli)\n",
    "output_eval_path = os.path.join(KB_PATH, \"all_student_evaluations.json\")\n",
    "with open(output_eval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_evaluations, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\nSemua hasil evaluasi disimpan di: {output_eval_path}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# BAGIAN BARU: Analisis Waktu Evaluasi\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Analisis Waktu Evaluasi ---\")\n",
    "\n",
    "# (5) Buat DataFrame dari data waktu dan simpan ke CSV\n",
    "timing_df = pd.DataFrame(timing_data)\n",
    "timing_csv_path = os.path.join(KB_PATH, \"evaluation_timing_report.csv\")\n",
    "timing_df.to_csv(timing_csv_path, index=False)\n",
    "print(f\"Laporan waktu evaluasi telah disimpan di: {timing_csv_path}\")\n",
    "\n",
    "# (6) Tampilkan 5 baris pertama (head) dari DataFrame waktu\n",
    "print(\"\\nCuplikan Laporan Waktu (5 baris pertama):\")\n",
    "print(timing_df.head())\n",
    "\n",
    "# Tampilkan statistik deskriptif\n",
    "print(\"\\nStatistik Waktu Evaluasi (detik):\")\n",
    "print(timing_df[\"evaluation_time_seconds\"].describe())\n",
    "\n",
    "# (7) Buat dan simpan visualisasi plot\n",
    "print(\"\\nMembuat visualisasi plot...\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 14))  # Membuat 2 plot dalam 1 gambar\n",
    "\n",
    "# Plot 1: Box Plot untuk Distribusi Waktu Keseluruhan\n",
    "sns.boxplot(x=timing_df[\"evaluation_time_seconds\"], ax=axes[0])\n",
    "axes[0].set_title(\"Distribusi Waktu Evaluasi per Jawaban\", fontsize=16)\n",
    "axes[0].set_xlabel(\"Waktu (detik)\", fontsize=12)\n",
    "\n",
    "# Plot 2: Bar Plot untuk Rata-rata Waktu per Soal\n",
    "avg_time_per_question = (\n",
    "    timing_df.groupby(\"question_id\")[\"evaluation_time_seconds\"].mean().sort_index()\n",
    ")\n",
    "avg_time_per_question.plot(\n",
    "    kind=\"bar\",\n",
    "    ax=axes[1],\n",
    "    color=sns.color_palette(\"viridis\", len(avg_time_per_question)),\n",
    ")\n",
    "axes[1].set_title(\"Rata-rata Waktu Evaluasi per Soal\", fontsize=16)\n",
    "axes[1].set_xlabel(\"ID Soal\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Rata-rata Waktu (detik)\", fontsize=12)\n",
    "axes[1].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "# Simpan gambar plot\n",
    "plot_path = os.path.join(KB_PATH, \"evaluation_timing_plot.png\")\n",
    "plt.savefig(plot_path)\n",
    "print(f\"Plot visualisasi waktu telah disimpan di: {plot_path}\")\n",
    "\n",
    "# Tampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BAGIAN 3.4 (REVISI): PERSIAPAN DATA UNTUK EVALUASI RAGAS\n",
    "# ==============================================================================\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "print(\"Memulai persiapan data untuk evaluasi RAGAs dengan ground truth kustom...\")\n",
    "\n",
    "\n",
    "def load_ground_truth_from_docx(file_path):\n",
    "    \"\"\"\n",
    "    Membaca file .docx yang berisi string JSON, membersihkannya,\n",
    "    dan mem-parse-nya dengan lebih tangguh.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        full_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "        # Membersihkan teks dari spasi berlebih di awal/akhir\n",
    "        cleaned_text = full_text.strip()\n",
    "\n",
    "        # ---- PERBAIKAN UTAMA DIMULAI DI SINI ----\n",
    "        # Jika teks tidak kosong dan belum menjadi array JSON yang valid\n",
    "        if cleaned_text and not (\n",
    "            cleaned_text.startswith(\"[\") and cleaned_text.endswith(\"]\")\n",
    "        ):\n",
    "            # Bungkus dengan kurung siku untuk menjadikannya array JSON yang valid\n",
    "            json_array_string = f\"[{cleaned_text}]\"\n",
    "        else:\n",
    "            json_array_string = cleaned_text\n",
    "        # ---- AKHIR PERBAIKAN ----\n",
    "\n",
    "        # Coba parse string yang sudah diperbaiki\n",
    "        return json.loads(json_array_string)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File ground truth tidak ditemukan di {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ERROR: Gagal mem-parse JSON dari file {file_path}.\")\n",
    "        print(f\"Detail Error: {e}\")\n",
    "        # Tambahan: Tampilkan beberapa karakter pertama dari teks yang bermasalah\n",
    "        print(\"Teks yang bermasalah (100 karakter pertama):\")\n",
    "        print(repr(json_array_string[:100]))\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error saat membaca file ground truth: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Path ke file ground truth Anda\n",
    "ground_truth_path = os.path.join(KB_PATH, \"ground_truth/gt_mahasiswa1.docx\")\n",
    "\n",
    "# Muat data ground truth\n",
    "ground_truth_list = load_ground_truth_from_docx(ground_truth_path)\n",
    "\n",
    "# Ubah ground truth menjadi dictionary yang mudah diakses dengan key 'question_id'\n",
    "if ground_truth_list:\n",
    "    ground_truth_map = {item[\"question_id\"]: item for item in ground_truth_list}\n",
    "    print(f\"Berhasil memuat {len(ground_truth_map)} data ground truth.\")\n",
    "\n",
    "    # Siapkan data untuk RAGAs\n",
    "    data_for_ragas = []\n",
    "    # `all_evaluations` adalah variabel dari hasil eksekusi RAG Anda sebelumnya\n",
    "    # Kita hanya akan mengevaluasi mahasiswa yang ada di ground truth (M1)\n",
    "    if \"M1\" in all_evaluations:\n",
    "        for question_id, rag_output in all_evaluations[\"M1\"].items():\n",
    "            if question_id in ground_truth_map:\n",
    "                gt_data = ground_truth_map[question_id]\n",
    "                question_text = next(\n",
    "                    (\n",
    "                        q[\"question_text\"]\n",
    "                        for q in question_data\n",
    "                        if q[\"question_id\"] == question_id\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                if question_text:\n",
    "                    data_for_ragas.append(\n",
    "                        {\n",
    "                            \"question\": question_text,\n",
    "                            \"answer\": rag_output[\n",
    "                                \"gemma_evaluation\"\n",
    "                            ],  # Jawaban dari sistem RAG Anda\n",
    "                            \"contexts\": [\n",
    "                                ctx.strip()\n",
    "                                for ctx in rag_output[\"retrieved_context\"].split(\"###\")\n",
    "                                if ctx.strip()\n",
    "                            ],\n",
    "                            \"ground_truth\": gt_data[\n",
    "                                \"gemini_evaluation\"\n",
    "                            ],  # Jawaban ideal dari file GT\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    if data_for_ragas:\n",
    "        # Buat dataset\n",
    "        ragas_dataset = Dataset.from_list(data_for_ragas)\n",
    "        print(\"\\nDataset untuk evaluasi RAGAs berhasil dibuat:\")\n",
    "        print(ragas_dataset)\n",
    "        # Konversi ke DataFrame untuk digunakan di blok-blok berikutnya\n",
    "        evaluation_df = ragas_dataset.to_pandas()\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nTidak ada data yang cocok antara hasil evaluasi RAG dan ground truth. Evaluasi tidak dapat dilanjutkan.\"\n",
    "        )\n",
    "        evaluation_df = pd.DataFrame()  # Buat DataFrame kosong\n",
    "else:\n",
    "    print(\"\\nEvaluasi tidak dapat dilanjutkan karena gagal memuat ground truth.\")\n",
    "    evaluation_df = pd.DataFrame()  # Buat DataFrame kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.5: EVALUASI GENERATION - FAITHFULNESS\n",
    "# ==============================================================================\n",
    "import os\n",
    "\n",
    "os.environ[\"RAGAS_DEBUG\"] = \"true\"\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "\n",
    "# sbert_model_name = 'sonoisa/sentence-bert-base-ja-mean-tokens'\n",
    "\n",
    "if not evaluation_df.empty:\n",
    "    print(\"Mengevaluasi metrik: Faithfulness...\")\n",
    "\n",
    "    gemma_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=gemma_model,\n",
    "        tokenizer=gemma_tokenizer,\n",
    "        max_new_tokens=128,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        batch_size=16,\n",
    "        truncation=True,\n",
    "    )\n",
    "    langchain_llm = HuggingFacePipeline(pipeline=gemma_pipeline)\n",
    "\n",
    "    run_config = RunConfig(timeout=60, log_tenacity=True)\n",
    "    ragas_llm = LangchainLLMWrapper(langchain_llm, run_config)\n",
    "\n",
    "    # Inisialisasi embeddings\n",
    "    sbert_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    hf_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=sbert_model_name, model_kwargs={\"device\": \"cuda\"}\n",
    "    )\n",
    "\n",
    "    print(\"Komponen siap. Mengevaluasi metrik: Faithfulness...\")\n",
    "    print(evaluation_df)\n",
    "\n",
    "    result_faithfulness = evaluate(\n",
    "        dataset=Dataset.from_pandas(evaluation_df),\n",
    "        metrics=[faithfulness],\n",
    "        llm=ragas_llm,\n",
    "        embeddings=hf_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae58abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.5.1: UJI COBA DENGAN DATASET MINI UNTUK DEBUGGING\n",
    "# ==============================================================================\n",
    "# Blok ini bertujuan untuk menguji alur evaluasi dengan data yang paling\n",
    "# sederhana untuk melihat apakah error Timeout/KeyError tetap terjadi.\n",
    "\n",
    "print(\"--- Memulai Uji Coba dengan Dataset Mini ---\")\n",
    "\n",
    "# (1) Membuat dataset yang sangat pendek dan sederhana\n",
    "# Strukturnya sama persis, tetapi isinya hanya satu kata.\n",
    "# Faithfulness harusnya mudah memverifikasi bahwa \"Biru\" ada di dalam konteks.\n",
    "mini_data_samples = {\n",
    "    \"question\": [\"Is blue a color?\"],\n",
    "    \"answer\": [\"Yes it is\"],\n",
    "    \"contexts\": [[\"Blue in one of color\"]],\n",
    "    \"ground_truth\": [\"Yes, blues is a color\"],  # Tetap sertakan untuk konsistensi\n",
    "}\n",
    "mini_dataset = Dataset.from_dict(mini_data_samples)\n",
    "\n",
    "print(\"Dataset mini berhasil dibuat:\")\n",
    "print(mini_dataset)\n",
    "\n",
    "# (2) Menjalankan evaluasi pada dataset mini\n",
    "# Kita menggunakan kembali `langchain_llm_for_eval` dan `ragas_embeddings_wrapper`\n",
    "# yang sudah dibuat di blok sebelumnya.\n",
    "try:\n",
    "    print(\"\\nMengevaluasi 'faithfulness' pada dataset mini...\")\n",
    "\n",
    "    # Ambil metrik faithfulness yang sudah dikonfigurasi jika ada,\n",
    "    # atau cukup gunakan metrik mentah jika menjalankan blok ini secara terpisah\n",
    "    # Untuk keamanan, kita gunakan metrik mentah saja di sini.\n",
    "    print(\"Mengevaluasi metrik: Faithfulness...\")\n",
    "\n",
    "    gemma_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=gemma_model,\n",
    "        tokenizer=gemma_tokenizer,\n",
    "        max_new_tokens=128,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        batch_size=16,\n",
    "        truncation=True,\n",
    "    )\n",
    "    langchain_llm = HuggingFacePipeline(pipeline=gemma_pipeline)\n",
    "\n",
    "    run_config = RunConfig(timeout=60, log_tenacity=True)\n",
    "    ragas_llm = LangchainLLMWrapper(langchain_llm, run_config)\n",
    "\n",
    "    # Inisialisasi embeddings\n",
    "    sbert_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    hf_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=sbert_model_name, model_kwargs={\"device\": \"cuda\"}\n",
    "    )\n",
    "\n",
    "    print(\"Komponen siap. Mengevaluasi metrik: Faithfulness...\")\n",
    "\n",
    "    result_faithfulness = evaluate(\n",
    "        dataset=mini_dataset,\n",
    "        metrics=[faithfulness],\n",
    "        llm=ragas_llm,\n",
    "        embeddings=hf_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nUji coba GAGAL dengan error: {e}\")\n",
    "\n",
    "print(\"\\n--- Uji Coba Selesai ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_df = result_faithfulness.to_pandas()\n",
    "print(\"Evaluasi Faithfulness Selesai.\")\n",
    "print(faithfulness_df[[\"question\", \"answer\", \"faithfulness_score\"]].head())\n",
    "\n",
    "if \"faithfulness_score\" in faithfulness_df.columns:\n",
    "    evaluation_df = pd.merge(\n",
    "        evaluation_df,\n",
    "        faithfulness_df[[\"question\", \"faithfulness_score\"]],\n",
    "        on=\"question\",\n",
    "        how=\"left\",  # Gunakan left merge untuk menjaga semua baris asli\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'faithfulness_score' column not found in faithfulness_df after evaluation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8046f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.6: UJI COBA 'ANSWER_RELEVANCY' (DENGAN MODEL GEMMA LOKAL)\n",
    "# ==============================================================================\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "\n",
    "# Impor metrik yang akan diuji\n",
    "from ragas.metrics import answer_relevancy\n",
    "\n",
    "# Impor semua wrapper dan komponen yang diperlukan\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "if not evaluation_df.empty:\n",
    "    print(\"--- Memulai Uji Coba Metrik: Answer Relevancy (dengan Gemma Lokal) ---\")\n",
    "\n",
    "    try:\n",
    "        # (1) Konfigurasi Eksekusi\n",
    "        run_config = RunConfig(\n",
    "            timeout=600, log_tenacity=True\n",
    "        )  # Gunakan timeout panjang untuk keamanan\n",
    "\n",
    "        # (2) Penyiapan LLM (sesuai format yang Anda minta)\n",
    "        gemma_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=gemma_model,\n",
    "            tokenizer=gemma_tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            batch_size=16,\n",
    "        )\n",
    "\n",
    "        print(\"\\nMengevaluasi 'answer_relevancy'...\")\n",
    "        result_relevancy = evaluate(\n",
    "            dataset=Dataset.from_pandas(evaluation_df),\n",
    "            metrics=[answer_relevancy],\n",
    "            llm=ragas_llm,\n",
    "            embeddings=hf_embeddings,\n",
    "            raise_exceptions=False,\n",
    "        )\n",
    "\n",
    "        relevancy_df = result_relevancy.to_pandas()\n",
    "        print(\"\\nEvaluasi 'answer_relevancy' SELESAI.\")\n",
    "        print(\"Hasil:\")\n",
    "        display(relevancy_df)\n",
    "\n",
    "        # (Opsional) Gabungkan skor ke DataFrame utama\n",
    "        score_col = \"answer_relevancy_score\"\n",
    "        if score_col in relevancy_df.columns:\n",
    "            evaluation_df = pd.merge(\n",
    "                evaluation_df,\n",
    "                relevancy_df[[\"question\", score_col]],\n",
    "                on=\"question\",\n",
    "                how=\"left\",\n",
    "            )\n",
    "            print(f\"\\nSkor '{score_col}' berhasil digabungkan.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nUji coba 'answer_relevancy' GAGAL dengan error: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame evaluasi kosong, melewati blok 3.6.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.8: EVALUASI RETRIEVAL - CONTEXT RECALL\n",
    "# ==============================================================================\n",
    "from ragas.metrics import context_recall\n",
    "\n",
    "if not evaluation_df.empty:\n",
    "    print(\"\\nMengevaluasi metrik: Context Recall...\")\n",
    "    result_recall = evaluate(\n",
    "        dataset=Dataset.from_pandas(evaluation_df),\n",
    "        metrics=[context_recall],\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    recall_df = result_recall.to_pandas()\n",
    "    print(\"Evaluasi Context Recall Selesai.\")\n",
    "    print(recall_df[[\"question\", \"ground_truth\", \"context_recall_score\"]].head())\n",
    "\n",
    "    # Gabungkan hasil ke DataFrame utama\n",
    "    evaluation_df = pd.merge(\n",
    "        evaluation_df, recall_df[[\"question\", \"context_recall_score\"]], on=\"question\"\n",
    "    )\n",
    "else:\n",
    "    print(\"DataFrame evaluasi kosong, melewati blok 3.8.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b36280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.7: EVALUASI RETRIEVAL - CONTEXT PRECISION\n",
    "# ==============================================================================\n",
    "from ragas.metrics import context_precision\n",
    "\n",
    "if not evaluation_df.empty:\n",
    "    print(\"\\nMengevaluasi metrik: Context Precision...\")\n",
    "    result_precision = evaluate(\n",
    "        dataset=Dataset.from_pandas(evaluation_df),\n",
    "        metrics=[context_precision],\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    precision_df = result_precision.to_pandas()\n",
    "    print(\"Evaluasi Context Precision Selesai.\")\n",
    "    print(precision_df[[\"question\", \"contexts\", \"context_precision_score\"]].head())\n",
    "\n",
    "    # Gabungkan hasil ke DataFrame utama\n",
    "    evaluation_df = pd.merge(\n",
    "        evaluation_df,\n",
    "        precision_df[[\"question\", \"context_precision_score\"]],\n",
    "        on=\"question\",\n",
    "    )\n",
    "else:\n",
    "    print(\"DataFrame evaluasi kosong, melewati blok 3.7.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66707703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLOK 3.9: AGREGASI, VISUALISASI, DAN PENYIMPANAN HASIL\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if not evaluation_df.empty and \"faithfulness_score\" in evaluation_df.columns:\n",
    "    print(\"\\n--- HASIL AKHIR EVALUASI RAG ---\")\n",
    "\n",
    "    # Pilih kolom skor untuk ditampilkan\n",
    "    score_columns = [\n",
    "        \"faithfulness_score\",\n",
    "        \"answer_relevancy_score\",\n",
    "        \"context_precision_score\",\n",
    "        \"context_recall_score\",\n",
    "    ]\n",
    "    final_results_df = evaluation_df[[\"question\"] + score_columns]\n",
    "\n",
    "    print(\"\\nTabel Hasil Akhir:\")\n",
    "    print(final_results_df)\n",
    "\n",
    "    # Menghitung skor rata-rata\n",
    "    average_scores = final_results_df[score_columns].mean().reset_index()\n",
    "    average_scores.columns = [\"Metric\", \"Average Score\"]\n",
    "\n",
    "    print(\"\\nSkor Rata-Rata per Metrik:\")\n",
    "    print(average_scores)\n",
    "\n",
    "    # --- Visualisasi Data ---\n",
    "    print(\"\\nMembuat visualisasi hasil evaluasi...\")\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    sns.barplot(\n",
    "        x=\"Average Score\", y=\"Metric\", data=average_scores, ax=ax, palette=\"viridis\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Rata-Rata Skor Metrik Evaluasi RAG\", fontsize=16)\n",
    "    ax.set_xlabel(\"Rata-Rata Skor\", fontsize=12)\n",
    "    ax.set_ylabel(\"Metrik\", fontsize=12)\n",
    "    ax.set_xlim(0, 1)  # Skor RAGAs berada dalam rentang 0 hingga 1\n",
    "\n",
    "    # Menambahkan label pada bar\n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i, fmt=\"%.3f\", padding=3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Simpan gambar\n",
    "    figure_path = os.path.join(KB_PATH, \"ragas_evaluation_summary.png\")\n",
    "    plt.savefig(figure_path)\n",
    "    print(f\"Gambar grafik telah disimpan di: {figure_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Penyimpanan Hasil Akhir ---\n",
    "    # Simpan DataFrame lengkap ke file CSV\n",
    "    output_csv_path = os.path.join(KB_PATH, \"ragas_full_evaluation_results.csv\")\n",
    "    evaluation_df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\n",
    "        f\"\\nLaporan evaluasi lengkap telah disimpan dalam format CSV di: {output_csv_path}\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"\\nTidak ada hasil untuk divisualisasikan atau disimpan.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
